<!DOCTYPE html>
<html lang="en">
    
    <head>
        <meta charset="UTF-8">
        <title>Teachable Machine</title>
        <meta name="viewport" content="width=device-width,initial-scale=1">
        <link rel="stylesheet" href="styles.css">
    </head>

    <body>
        <nav style="text-align: center;">
            <p>
                <a class="m-2" href="index.html">Welcome</a>
                <a class="m-2" href="about.html">About Us</a>
                <a class="m-2" href="library.html">Resource Library</a>
                <a class="m-2" href="heroes.html">Tech Heroes</a>
                <a class="m-2" href="tm.html">Teachable Machine</a>
            </p>
        </nav>

        <main>
            <h1>
                Teachable Machine
            </h1>
        
            <!-- Demo videos from youtube-->
            <div style="text-align:center; margin: 20px 0;">
                <h2>Demo Videos</h2>
              
                <!-- First video from the teachable machine website-->
                <iframe width="560" height="315"
                  src="https://www.youtube.com/embed/AZ9enhzqltE"
                  title="Training Demo"
                  frameborder="0"
                  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                  allowfullscreen>
                </iframe>
                
                <!-- Second video with the emojis-->
                <iframe width="560" height="315"
                src="https://www.youtube.com/embed/54DbFHfKS7g"
                title="Emoji Model Demo"
                frameborder="0"
                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                allowfullscreen>
              </iframe>

              <p>
                Try our Teachable Machine here:
                <a href="https://teachablemachine.withgoogle.com/models/KLc6XPVWu/" target="_blank">
                  Open Teachable Machine Model
                </a>
              </p>

              </div>

            <div class="page-title">
                <h2>Our Project Statement</h2>
            </div>
            <!-- First Project3 revision: imporoving text readability in the code-->
            <!-- Added headers to the Project Statement for better clarity-->
            <div class="description">
                <p>
                        Throughout the duration of this course, we explored a variety of 
                        concepts related to the dynamics of power in technology and computing. 
                        We focused particularly on machine learning algorithms, and analyzed 
                        the many unspoken ways these algorithms functioned as extensions of 
                        prejudice against users of color. Using Joy Buolamwini’s Unmasking AI, 
                        we learned of the danger of biased machine learning algorithms left 
                        unchecked. The original idea for our Teachable Machine was to have it 
                        differentiate between different books and stuffed animals with captions 
                        underneath, more or less in the same style as the demonstration video. 
                        However, after taking our own photos and beginning to work on the 
                        project, we came to the realization that with the mix of the project 
                        statement part and directions for the assignment, this idea would not 
                        have made the most sense as it’s not really connecting to anything we 
                        learned in class or to any of the readings. It also didn’t connect to 
                        Joy Buolamwini’s Unmasking AI in any way. After some talking we changed 
                        the idea of our teachable machine from books and stuffed animals to 
                        create a facial-expression recognition model that responds in real 
                        time to a person looking into the camera. 
                </p>
                <h2>Model Design and Function</h2>
                <p>
                        Our revised project aimed to train the model on five basic emotions: 
                        happy, sad, angry, neutral, and eyebrow raise. When the camera scans 
                        a user’s face, the system identifies the expression and displays a 
                        matching emoji on the side of the screen. The project goal is to make 
                        emotion detection simple and visual, using emojis as an easy way for 
                        users to understand the output. Each emotion category will contain 
                        multiple example images from the user’s webcam to help the Teachable 
                        Machine learn the differences between expressions. After training, 
                        the model will be exported and integrated into a simple web/app 
                        interface so users can see their expression change in real time. 
                        This approach works well because it is visual, interactive, and fun 
                        but also demonstrates how machine learning can classify patterns in 
                        human facial movement. 
                        
                        Practical real world applications of this technology include early
                         childhood classroom settings, where students 
                        could practice their social emotional learning through identifying and 
                        recognizing the various facial expressions, and as an aid for those 
                        with differing abilities to better engage with the world around them. 
                        While working on my facial expression Teachable Machine, I began to 
                        notice how fragile the model was. It performed well in the Teachable 
                        Machine interface, but when I exported it into p5.js, its accuracy 
                        immediately dropped. This connection reminded me of Joy Buolamwini’s 
                        experience in “Unmasking AI” where she repeatedly shows that models 
                        often work in carefully controlled environments but fail in real world 
                        conditions. Like Joy’s description of the “coded gaze” where I saw how 
                        my own model depended heavily on lighting, angle, facial features, and 
                        the fact that we only trained it on one person’s face. If someone else 
                        with a different skin tone, facial features, or lighting stood in front
                         of the model, it might not read their expression correctly at all. 
                         This made me more aware of how easily AI systems can misinterpret or 
                         even exclude people, even when the project seems small or harmless. 
                         One of the most important things I learned while building my model 
                         was how strongly accuracy depends on dataset size. At first, I 
                         collected around 5-15 images for each emotion assuming that the 
                         Teachable Machine would handle the rest. But the model was quite 
                         unstable. Angry and Eyebrow Raise were constantly getting mixed up 
                         and Neutral rarely registered correctly. I realized that the model 
                         was not actually learning the emotional categories, it was memorizing 
                         small cues from a tiny dataset. It wasn’t until I added more pictures 
                         to each class to over 100 examples (121 happy, 100 sad, 103 angry, 
                         122 neutral, and 122 eyebrow raise) that the model’s prediction 
                         became more reliable. This experience helped me understand one of 
                         Buolamwini’s central arguments in Unmasking AI that machine learning 
                         systems are only as good as the data they are trained on. Just as 
                         facial recognition systems fail on populations that are 
                         underrepresented in the training data, my model failed until each 
                         category was represented with enough data. Even a simple emotion 
                         recognition project showed me that insufficient data leads to 
                         misclassification and fragile performance, exactly the kind of issues 
                         Joy warns about on a much larger scale.
                </p>

                <p>
                    Our teachable machine relates to Joy Buolamwini’s “Unmasking AI” as it 
                    directly looks at the idea of Bias in Facial Recognition. Instances in 
                    recent years mentioned by Buolamwini include a woman on vacation in Las 
                    Vegas who was approached by security for being a sex worker and what 
                    happened was the facial recognition software in the camera had an error 
                    and mixed up this lady with another person (Buolamwini, 2023, p. 71). 
                    This also relates to Buolamwini’s research done at MIT where their facial 
                    recognition machine failed to recognize her face unless she was wearing a 
                    white mask. In addition to this instance, there are countless others that 
                    demonstrate how dangerous it is to have functioning algorithms that reflect
                     bias of any kind. The most harrowing possibility of this being law 
                     enforcement’s use of facial recognition technology as a means of 
                     surveillance. When we are proactive about preventing algorithmic bias, 
                     we ensure that everyone who engages with the tech is able to do so 
                     equitably. 
                </p>

                <p>
                    An overarching lesson we found ourselves returning to was the need for 
                    facial recognition and machine learning algorithms to be applied equitably 
                    to communities of color. This notion of equity was demonstrated through 
                    Buolamwini’s exploration of algorithmic bias in machine learning algorithms 
                    and through the tech heroes we covered throughout the semester. The 
                    potential for algorithmic bias to adversely affect persons of color 
                    abound when we consider the many different ways machine learning 
                    technologies impact our daily lives, like in medical, legal, and 
                    even academic contexts. One of the most notable examples from Unmasking AI 
                    was a medical application where the organ donor recipient was overlooked 
                    on account of their race. 
                </p>
            </div>
        </main>

    </body>
</html>
